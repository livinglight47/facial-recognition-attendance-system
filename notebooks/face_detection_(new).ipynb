{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8591f729",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "from ultralytics import YOLO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e667799e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Device\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"Using device:\", device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d590ed64",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Project structure\n",
    "PROJECT_ROOT = os.path.dirname(os.getcwd())\n",
    "DATA_PATH = os.path.join(PROJECT_ROOT, \"data\", \"widerface_yolo\")\n",
    "\n",
    "IMAGES_DIR = os.path.join(DATA_PATH, \"images\")\n",
    "LABELS_DIR = os.path.join(DATA_PATH, \"labels\")\n",
    "\n",
    "IMAGES_TRAIN_DIR = os.path.join(IMAGES_DIR, \"train\")\n",
    "IMAGES_VAL_DIR = os.path.join(IMAGES_DIR, \"val\")\n",
    "\n",
    "LABELS_TRAIN_DIR = os.path.join(LABELS_DIR, \"train\")\n",
    "LABELS_VAL_DIR = os.path.join(LABELS_DIR, \"val\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e995cfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "for p in (IMAGES_TRAIN_DIR, IMAGES_VAL_DIR, LABELS_TRAIN_DIR, LABELS_VAL_DIR):\n",
    "    if not os.path.exists(p):\n",
    "        print(\"WARNING: path does not exist:\", p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d30a13ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "yaml_path = os.path.join(DATA_PATH, \"face_detection.yaml\")\n",
    "with open(yaml_path, \"w\") as f:\n",
    "    f.write(f\"\"\"\n",
    "path: {DATA_PATH}\n",
    "train: images/train\n",
    "val: images/val\n",
    "nc: 1\n",
    "names: ['face']\n",
    "\"\"\")\n",
    "print(\"YAML file created at:\", yaml_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a351a559",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = YOLO(\"yolo11m.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb633cfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_PATH = os.path.join(PROJECT_ROOT, \"models\", \"face_detection_new\", \"yolo11m.pt\")\n",
    "MODEL_RUNS_DIR = os.path.join(PROJECT_ROOT, \"models\", \"face_detection_new\", \"runs\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70ce69d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = YOLO(MODEL_PATH)\n",
    "print(\"Loaded model:\", model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6e8cf25",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = model.train(\n",
    "    # DATA & MODEL\n",
    "    data=yaml_path,\n",
    "    model=MODEL_PATH,\n",
    "    pretrained=True,\n",
    "\n",
    "    # EPOCHS & IMAGE SIZE\n",
    "    epochs=200,                # allow proper convergence; early stop will cut it sooner if needed\n",
    "    imgsz=640,                 # â†‘ accuracy; if OOM -> 512 or 448\n",
    "    batch=8,                   # keep small for low VRAM\n",
    "    workers=2,                 # Windows-friendly\n",
    "\n",
    "    # OPTIMIZATION\n",
    "    optimizer=\"AdamW\",\n",
    "    lr0=7e-4,                  # slightly lower than 1e-3 for stability on small batches\n",
    "    lrf=0.01,                  # final LR factor for cosine\n",
    "    cos_lr=True,               # cosine LR schedule\n",
    "    warmup_epochs=3,\n",
    "    weight_decay=0.01,\n",
    "    patience=20,               # early stop window (validation-based)\n",
    "    amp=True,                  # mixed precision if GPU supports; silently falls back if not\n",
    "\n",
    "    # AUGMENTATION (moderate, classroom-friendly)\n",
    "    multi_scale=True,          # random scale each batch (good for small/varied faces)\n",
    "    degrees=15.0,              # slight rotations for tilted heads\n",
    "    shear=10.0,\n",
    "    perspective=0.0005,\n",
    "    translate=0.10,\n",
    "    scale=0.4,                # allow zoom in/out\n",
    "    fliplr=0.5,                # horizontal flips are fine; avoid vertical flips for faces\n",
    "    flipud=0.0,\n",
    "    hsv_h=0.015, hsv_s=0.7, hsv_v=0.4,\n",
    "    mosaic=0.2,                # light mosaic (too much can distort faces)\n",
    "    mixup=0.00,                # small; higher can hurt face boxes\n",
    "    copy_paste=0.0,            # not great for faces\n",
    "\n",
    "    # LOSS BALANCING (single class)\n",
    "    box=7.5,                   # emphasize localization\n",
    "    cls=0.2,                   # down-weight classification (only one class)\n",
    "    dfl=1.5,\n",
    "\n",
    "    # PROJECT STRUCTURE\n",
    "    project=MODEL_RUNS_DIR,\n",
    "    name=\"face_yolo11m\",\n",
    "\n",
    "    # STORAGE / HOUSEKEEPING\n",
    "    save=True,                 # keep final weights\n",
    "    save_period=-1,            \n",
    "    exist_ok=True,\n",
    "    cache=False,\n",
    "    plots=False,\n",
    "    verbose=False,\n",
    "\n",
    "    # DEVICE\n",
    "    device=0                   # GPU 0; set \"cpu\" if necessary\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "593c125c",
   "metadata": {},
   "source": [
    "# DON'T TOUCH BELOW #"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "969f174f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# RESUME TRAINING FROM CHECKPOINT\n",
    "# Point to the 'last.pt' of your crashed run\n",
    "resume_model_path = os.path.join(MODEL_RUNS_DIR , \"face_yolo11s\", \"weights\", \"last.pt\")\n",
    "\n",
    "model = YOLO(resume_model_path)\n",
    "\n",
    "# Resume training from where it stopped\n",
    "results = model.train(\n",
    "    resume=True,               # <--- this is the key\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a11d19c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics = model.val()  # runs validation and returns metrics dict\n",
    "print(\"Validation metrics:\", metrics)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
